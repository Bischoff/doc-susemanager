<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
                 type="text/xml" 
                 title="Profiling step"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="bp.chapt.suma3.troubleshooting">
    <title>Troubleshooting</title>

    <sect1 xml:id="bp.chapt.suma3.troubleshooting.registering.cloned.salt.systems">
        <title>Registering Cloned Salt Systems (minions)</title>

        <para>This chapter provides guidance on registering cloned systems with SUSE Manager. This
            includes both Salt and Traditional clients.</para>

        <procedure>
            <title>Registering a Cloned System with SUSE Manager (Salt)</title>
            <step>
                <para> Clone your system (for example using the existing cloning mechanism of your
                    favorite Hypervisor)</para>
                <note>
                    <title>Quick Tips</title>
                    <para>Each step in this section is performed on the cloned system, this
                        procedure does not manipulate the original system, which will still be
                        registered to SUSE Manager. The cloned virtual machine should have a
                        different UUID from the original (this UUID is generated by your hypervisor)
                        or SUSE Manager will overwrite the original system data with the new
                        one.</para>
                </note>
            </step>
            <step>
                <para>Make sure your machines have different hostnames and IP addresses, also check
                    that /etc/hosts contains the changes you made and the correct host
                    entries.</para>
            </step>
            <step>
                <para>Stop rhnsd daemon with:</para>
                <screen># /etc/init.d/rhnsd stop </screen>
                <para>or alternativly:</para>
                <screen># rcrhnsd stop</screen>
            </step>
            <step>
                <para>Stop osad with:</para>
                <screen># /etc/init.d/osad stop</screen>
                <para>or alternativly:</para>
                <screen># rcosad stop</screen>
            </step>
            <step>
                <para>Remove the osad authentication configuration file and the systemid
                    with:</para>
                <screen># rm -f /etc/sysconfig/rhn/{osad-auth.conf,systemid}</screen>
            </step>

        </procedure>

        <para>The next step you take will depend on the Operating System of the clone.</para>
        <para>In case the following scenario occurs: If you see only one of your cloned Salt minions
            on the System Overview page after having accepted all minions keys from the Salt
            Onboarding page, then this is likely due to these machines being clones of the original
            and utilizing a duplicate machine-id. Perform the following steps to resolve this
            conflict.</para>

        <procedure>
            <title>Registering Salt Clones: SLES 12</title>
            <step>
                <para>SLES 12: If your machines have the same machine ids then delete the file on
                    each minion and recreate it:</para>
                <screen># cat /etc/machine-id
# rm /etc/machine-id
# systemd-machine-id-setup</screen>
            </step>
        </procedure>

        <procedure>
            <title>Registering Salt Clones: SLES 11</title>
            <step>
                <para>SLES 11: As there is no systemd machine id, generate one from dbus:</para>
                <screen># cat /var/lib/dbus/machine-id
# rm /var/lib/dbus/machine-id
# dbus-uuidgen --ensure</screen>
            </step>
        </procedure>

        <para> If your machines still have the same minion id then delete the minion_id file on each
            minion (FQDN will be used when it is regenerated on minion restart):</para>
        <screen># rm /etc/salt/minion_id</screen>
        <para>Finally delete accepted keys from Onboarding page and system profile from SUSE
            Manager, and restart the minion with:</para>
        <screen># systemctl restart salt-minion</screen>
        <para> You should be able to re-register them again, but each minion will use a different
            '/etc/machine-id' and should now be correctly displayed on the System Overview page. </para>

    </sect1>
    <sect1 xml:id="bp.chapt.suma3.troubleshooting.registering.cloned.traditional.systems">
        <title>Registering Cloned Traditional Systems</title>
        <para> This section provides guidance on registering cloned traditional systems which are
            registered via bootstrap. </para>

        <procedure>
            <title>Registering a Cloned System with SUSE Manager (Traditional Systems)</title>
            <step>
                <para> Clone your system (using your favorite hypervisor.)</para>
                <note>
                    <title>Quick Tips</title>
                    <para>Each step in this section is performed on the cloned system, this
                        procedure does not manipulate the original system, which will still be
                        registered to SUSE Manager. The cloned virtual machine should have a
                        different UUID from the original (this UUID is generated by your hypervisor)
                        or SUSE Manager will overwrite the original system data with the new
                        one.</para>
                </note>
            </step>
            <step>
                <para>Change the Hostname and IP addresses, also make sure /etc/hosts contains the
                    changes you made and the correct host entries.</para>
            </step>
            <step>
                <para>Stop rhnsd daemon with:</para>
                <screen># /etc/init.d/rhnsd stop </screen>
                <para>or alternativly:</para>
                <screen># rcrhnsd stop</screen>
            </step>
            <step>
                <para>Stop osad with:</para>
                <screen># /etc/init.d/osad stop</screen>
                <para>or alternativly:</para>
                <screen># rcosad stop</screen>
            </step>
            <step>
                <para>Remove the osad authentifcation configuration file and the systemid
                    with:</para>
                <screen># rm -f /etc/sysconfig/rhn/{osad-auth.conf,systemid}</screen>
            </step>

        </procedure>
        <para>The next step you take will depend on the Operating System of the clone.</para>
        <procedure>
            <title>Registering A Cloned Traditional System: SLES 12</title>
            <step>
                <para>Remove the following credential files:</para>
                <screen># rm  -f /etc/zypp/credentials.d/{SCCcredentials,NCCcredentials}</screen>
            </step>
            <step>
                <para>Re-run the bootstrap script. You should now see the cloned system in SUSE
                    Manager without overwriting the system it was cloned from.</para>
            </step>

        </procedure>

        <procedure>
            <title>Registering A Cloned Traditional System: SLES 11</title>
            <step>
                <para>Continued from section 1 step 5:</para>
                <screen># suse_register -E</screen>
                <para> (--erase-local-regdata, Erase all local files created from a previous
                    executed registration. This option make the system look like never registered)
                </para>
            </step>
            <step>
                <para>Re-run the bootstrap script. You should now see the cloned system in SUSE
                    Manager without overwriting the system it was cloned from.</para>
            </step>
            <step>
                <para> Re-run the bootstrap script. You should now see the cloned system in SUSE
                    Manager without overwriting the system it was cloned from. </para>
            </step>

        </procedure>

        <procedure>
            <title>Registering A Cloned Traditional System: SLES 10</title>
            <step>
                <para>Continued from section 1 step 5:</para>
                <screen># rm -rf /etc/{zmd,zypp}</screen>

            </step>
            <step>
                <screen># rm -rf /var/lib/zypp/  # ¡¡¡¡¡ except /var/lib/zypp/db/products/ !!!!!</screen>
            </step>
            <step>
                <screen># rm -rf /var/lib/zmd/</screen>
            </step>
            <step>
                <para>Re-run the bootstrap script. You should now see the cloned system in SUSE
                    Manager without overwriting the system it was cloned from.</para>
            </step>

        </procedure>

        <procedure>
            <title>RHEL 5,6 and 7</title>
            <step>
                <para>Continued from section 1 step 5:</para>
                <screen># rm  -f /etc/NCCcredentials</screen>
            </step>
            <step>
                <para>Re-run the bootstrap script. You should now see the cloned system in SUSE
                    Manager without overwriting the system it was cloned from.</para>
            </step>
        </procedure>

    </sect1>

    <sect1 xml:id="bp.chapt.suma3.troubleshooting.osad.jabberd">

        <title>Typical OSAD/jabberd Challenges</title>
        <para> This section provides answers for typical issues regarding OSAD and jabberd. </para>

        <sect2>
            <title>Open File Count Exceeded</title>
            <para><literal>SYMPTOMS</literal>: OSAD clients cannot contact the SUSE Manager Server,
                and jabberd requires long periods of time to respond on port 5222.</para>

            <para><literal>CAUSE</literal>: The number of maximum files that a jabber user can open
                is lower than the number of connected clients. Each client requires one permanently
                open TCP connection and each connection requires one file handler. The result is
                jabberd begins to queue and refuse connections.</para>

            <para><literal>CURE</literal>: Edit the <filename>/etc/security/limits.conf</filename>
                to something similar to the following:
                <screen>jabbersoftnofile&lt;#clients + 100&gt;
jabberhardnofile&lt;#clients + 1000&gt;</screen>
            </para>

            <para>This will vary according to your setup. For example in the case of 5000 clients:
                <screen>jabbersoftnofile5100
jabberhardnofile6000</screen></para>

            <para> Ensure you update the <filename>/etc/jabberd/c2s.xml</filename> max_fds parameter
                as well. For example: <screen>&lt;max_fds&gt;6000&lt;/max_fds&gt;</screen></para>

            <para><literal>EXPLANATION</literal>: The soft file limit is the limit of the maximum
                number of open files for a single process. In SUSE Manager the highest consuming
                process is c2s, which opens a connection per client. 100 additional files are added,
                here, to accommodate for any non-connection file that c2s requires to work
                correctly. The hard limit applies to all processes belonging to the jabber user, and
                accounts for open files from the router, s2s and sm processes additionally. </para>

        </sect2>

        <sect2>
            <title>jabberd Database Corruption</title>
            <para><literal>SYMPTOMS</literal>: After a disk is full error or a disk crash event, the
                jabberd database may have become corrupted. jabberd may then fail to start during
                spacewalk-service start:
                <screen>Starting spacewalk services...
   Initializing jabberd processes...
       Starting router                                                                   done
       Starting sm startproc:  exit status of parent of /usr/bin/sm: 2                   failed
   Terminating jabberd processes...</screen></para>

            <para>/var/log/messages shows more details:
                <screen>jabberd/sm[31445]: starting up
jabberd/sm[31445]: process id is 31445, written to /var/lib/jabberd/pid/sm.pid
jabberd/sm[31445]: loading 'db' storage module
jabberd/sm[31445]: db: corruption detected! close all jabberd processes and run db_recover
jabberd/router[31437]: shutting down</screen></para>

            <para><literal>CURE</literal>: Remove the jabberd database and restart. Jabberd will
                automatically re-create the database.
                <screen> spacewalk-service stop
 rm -Rf /var/lib/jabberd/db/*
 spacewalk-service start</screen>
            </para>
            <para> An alternative approach would be to test another database, but SUSE Manager does
                not deliver drivers for this:
                <screen> rcosa-dispatcher stop
 rcjabberd stop
 cd /var/lib/jabberd/db
 rm *
 cp /usr/share/doc/packages/jabberd/db-setup.sqlite .
 sqlite3 sqlite.db &lt; db-setup.sqlite
 chown jabber:jabber *
 rcjabberd start
 rcosa-dispatcher start</screen>
            </para>

        </sect2>

        <sect2>
            <title>Capturing XMPP Network Data for Debugging Purposes</title>
            <para>If you are experiencing bugs regarding OSAD, it can be useful to dump network
                messages in order to help with debugging. The following procedures provide
                information on capturing data from both the client and server side. </para>

            <procedure>
                <title>Server Side Capture</title>
                <step>
                    <para>Install the <package>tcpdump</package> package on the SUSE Manager Server
                        as root: <command>zypper in tcpdump </command></para>
                </step>
                <step>
                    <para>Stop the OSA dispatcher and Jabber processes with
                            <command>rcosa-dispatcher stop</command> and <command>rcjabberd
                            stop.</command></para>
                </step>
                <step>
                    <para>Start data capture on port 5222: <command>tcpdump -s 0 port 5222 -w
                            server_dump.pcap</command></para>
                </step>
                <step>
                    <para>Start the OSA dispatcher and Jabber processes: <command>rcosa-dispatcher
                            start</command> and <command>rcjabberd start</command>.</para>
                </step>
                <step>
                    <para>Open a second terminal and execute the following commands:
                            <command>rcosa-dispatcher start</command> and <command>rcjabberd
                            start</command>.</para>
                </step>
                <step>
                    <para>Operate the SUSE Manager server and clients so the bug you formerly
                        experienced is reproduced.</para>
                </step>
                <step>
                    <para>One you have finished your capture re-open terminal 1 and stop the capture
                        of data with: <keycombo>
                            <keycap>CTRL</keycap>
                            <keycap>c</keycap>
                        </keycombo></para>
                </step>
            </procedure>

            <procedure>
                <title>Client Side Capture</title>
                <step>
                    <para>Install the tcpdump package on your client as root: <command>zypper in
                            tcpdump</command></para>
                </step>
                <step>
                    <para>Stop the OSA process: <command>rcosad stop</command>.</para>
                </step>
                <step>
                    <para>Begin data capture on port 5222: <command>tcpdump -s 0 port 5222 -w
                            client_client_dump.pcap</command></para>
                </step>
                <step>
                    <para>Open a second terminal and start the OSA process: <command>rcosad
                            start</command></para>
                </step>
                <step>
                    <para>Operate the SUSE Manager server and clients so the bug you formerly
                        experienced is reproduced.</para>
                </step>
                <step>
                    <para>Once you have finished your capture re-open terminal 1 and stop the
                        capture of data with: <keycombo>
                            <keycap>CTRL</keycap>
                            <keycap>c</keycap>
                        </keycombo></para>
                </step>
            </procedure>
        </sect2>

        <sect2>
            <title>Engineering Notes: Analyzing Captured Data</title>
            <para>This section provides information on analyzing the previously captured data from
                client and server.</para>
            <procedure>
                <step>
                    <para>Obtain the certificate file from your SUSE Manager server:
                        /etc/pki/spacewalk/jabberd/server.pem</para>
                </step>
                <step>
                    <para>Edit the certificate file removing all lines before <literal>----BEGIN RSA
                            PRIVATE KEY-----</literal>, save it as key.pem</para>
                </step>
                <step>
                    <para>Install Wireshark as root with: <command>zypper in
                        wireshark</command></para>
                </step>
                <step>
                    <para>Open the captured file in wireshark.</para>
                </step>
                <step>
                    <para>From <guimenu>Eidt</guimenu><guimenu>Preferences</guimenu> select SSL from
                        the left pane.</para>
                </step>
                <step>
                    <para>Select RSA keys list:
                            <guibutton>Edit</guibutton><guibutton>New</guibutton>
                        <itemizedlist>
                            <listitem>
                                <para>IP Address any</para>
                            </listitem>
                            <listitem>
                                <para>Port: 5222</para>
                            </listitem>
                            <listitem>
                                <para>Protocol: xmpp</para>
                            </listitem>
                            <listitem>
                                <para>Key File: open the key.pem file previously edited.</para>
                            </listitem>
                            <listitem>
                                <para>Password: leave blank</para>
                            </listitem>
                        </itemizedlist>
                    </para>
                    <para>For more information see also: <itemizedlist>
                            <listitem>
                                <para><link xlink:href="https://wiki.wireshark.org/SSL"/></para>
                            </listitem>
                            <listitem>
                                <para><link
                                        xlink:href="https://bugs.wireshark.org/bugzilla/show_bug.cgi?id=3444"
                                    /></para>
                            </listitem>
                        </itemizedlist></para>
                </step>
            </procedure>
        </sect2>

    </sect1>



</chapter>
